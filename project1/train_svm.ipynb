{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"elapsed":365,"status":"error","timestamp":1695689386642,"user":{"displayName":"Adrián García Sebastián","userId":"00421830482348579797"},"user_tz":-120},"id":"C9I1Ohpo9jHx","outputId":"47165fdd-b931-46c6-e1f7-a8e88519702a"},"outputs":[],"source":["import os\n","from paths import DATASET_IMG, FRONTAL, LATERAL, DATASET_CARS\n","import cv2\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import imutils\n","import math\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"R7c-F67J9jH4"},"outputs":[],"source":["FRONTALIMAGES = [str(FRONTAL / image_name) for image_name\n","                        in os.listdir(FRONTAL)]\n","\n","LATERALIMAGES = [str(LATERAL / image_name) for image_name\n","                        in os.listdir(LATERAL)]"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ja20Od7D9jH6"},"outputs":[],"source":["def preprocess_image(img_path):\n","    \"\"\"Preprocess the image and return required intermediates.\"\"\"\n","    # Read the image\n","    img = cv2.imread(img_path)\n","    # Convert image to grayscale\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # Noise reduction using bilateral filter\n","    bfilter = cv2.bilateralFilter(gray, 11, 17, 17)\n","    # Edge detection using Canny\n","    edged = cv2.Canny(bfilter, 30, 200)\n","    return img, gray, edged\n","\n","def find_license_plate_aspect_ratio(edged):\n","    \"\"\"Find and return the contour of the license plate.\"\"\"\n","    # Find contours in the edge-detected image\n","    keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","    contours = imutils.grab_contours(keypoints)\n","\n","    good_contours = []\n","    height, width = edged.shape\n","    # Calculating buffer in terms of pixels\n","    border_buffer_x = width * 0.1\n","    border_buffer_y = height * 0.1\n","    for contour in contours:\n","        x, y, w, h = cv2.boundingRect(contour)\n","        # Check if the contour is inside the buffered region\n","        if (x > border_buffer_x) and (x + w < width - border_buffer_x) and \\\n","           (y > border_buffer_y) and (y + h < height - border_buffer_y):\n","                #aspect_ratio = float(w) / h\n","                #if (1.2 < aspect_ratio < 8):\n","            good_contours.append(contour)\n","\n","    good_contours = sorted(good_contours, key=cv2.contourArea, reverse=True)[:200]\n","    return None if len(good_contours) == 0 else good_contours\n"]},{"cell_type":"markdown","metadata":{"id":"o-7QshWy9jH9"},"source":["### Method for obtaining things that are not license Plates"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"2Tlu0S-i9jIA"},"outputs":[],"source":["def distance_bounding_boxes(box1, box2):\n","    # Define the coordinates of the two bounding boxes as (x_min, y_min, x_max, y_max)\n","    (x_min1, y_min1, x_max1, y_max1) = box1\n","    (x_min2, y_min2, x_max2, y_max2) = box2\n","\n","    # Calculate the center coordinates of the two bounding boxes\n","    center1 = ((x_min1 + x_max1) / 2, (y_min1 + y_max1) / 2)\n","    center2 = ((x_min2 + x_max2) / 2, (y_min2 + y_max2) / 2)\n","\n","    # Define a distance threshold (you can adjust this as needed)\n","    distance_threshold = 10  # Adjust this threshold as needed\n","\n","    # Calculate the Euclidean distance between the centers of the two bounding boxes\n","    distance = math.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n","\n","    # Check if the distance is less than the threshold to determine if they are near\n","    if distance < distance_threshold:\n","       return True\n","    else:\n","        return False\n","\n","# Image for the cordiantes\n","def bounding_box_licensplate(xml_file):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    bndbox = root.find('.//bndbox')\n","    xmin = int(bndbox.find('xmin').text)\n","    ymin = int(bndbox.find('ymin').text)\n","    xmax = int(bndbox.find('xmax').text)\n","    ymax = int(bndbox.find('ymax').text)\n","    return ymin, xmin, ymax, xmax\n","\n","def obtain_negative_samples(xml_file, img, gray, locations):\n","    box1 = bounding_box_licensplate(xml_file)\n","    negativsamples = []\n","    for location in (locations):\n","        # A mask with the shape of the image that contains all 0\n","        mask = np.zeros(gray.shape, np.uint8)\n","        # In the mask put 1 in the locations specifed by location\n","        cv2.drawContours(mask, [location], 0, 255, -1)\n","        # Then in the original image mark the zone of interest with the mask\n","        cv2.bitwise_and(img, img, mask=mask)\n","        # Obatin the cordinates where the mask has 1 which is the locations that we are insterested\n","        (x, y) = np.where(mask==255)\n","        # Obtain the hight and the whith of the location\n","        (xmin, ymin) = (np.min(x), np.min(y))\n","        (xmax, ymax) = (np.max(x), np.max(y))\n","        box2 = (xmin, ymin, xmax, ymax)\n","        cropped_image = gray[xmin:xmax+1, ymin:ymax+1]\n","        # We stored those locations that are far from the licensplate\n","        if not distance_bounding_boxes(box1, box2):\n","            negativsamples.append(cropped_image)\n","    return negativsamples\n","\n","# Main method to process the image and visualize the results\n","def negative_samples(xml_path, img_path):\n","    img, gray, edged = preprocess_image(img_path)\n","    locations = find_license_plate_aspect_ratio(edged)\n","    if locations is None:\n","        print(\"Sorry, license plate not detected.\")\n","        return\n","    cropped_image_noise = obtain_negative_samples(xml_path, img, gray, locations)\n","    return cropped_image_noise\n","    #return img, locations # Returns the contours that SVM needs to classify"]},{"cell_type":"markdown","metadata":{"id":"0NLFqxVu9jIC"},"source":["### Method for obtaining the licensplates"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ZbqsuBSe9jID"},"outputs":[],"source":["def licensplate(xml_path, image_path):\n","    img = cv2.imread(image_path)\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n","    # Load XML from file\n","    tree = ET.parse(xml_path)\n","    root = tree.getroot()\n","    # Extract bounding box\n","    bndbox = root.find('.//bndbox')\n","    xmin = int(bndbox.find('xmin').text)\n","    ymin = int(bndbox.find('ymin').text)\n","    xmax = int(bndbox.find('xmax').text)\n","    ymax = int(bndbox.find('ymax').text)\n","\n","    licens_gray = img_gray[ymin:ymax, xmin:xmax]\n","    shape = licens_gray.shape\n","    if not 0 in shape:\n","        return licens_gray\n","    return None"]},{"cell_type":"markdown","metadata":{"id":"0dwsHo339jIE"},"source":["### Constructing the Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"02KYv6j39jIF"},"outputs":[],"source":["def read_files():\n","    xml_files, png_files = [], []\n","\n","    sorted_xml_dataset1 = sorted(os.listdir(DATASET_IMG / 'annotations'), key = lambda x: int(x[1:-4]))\n","    sorted_png_dataset1 = sorted(os.listdir(DATASET_IMG / 'images'), key = lambda x: int(x[1:-5]))\n","\n","    sorted_xml_dataset2 = sorted(os.listdir(DATASET_CARS / 'annotations'), key = lambda x: int(x[4:-4]))\n","    sorted_png_dataset2 = sorted(os.listdir(DATASET_CARS / 'images'), key = lambda x: int(x[4:-4]))\n","\n","    for png, xml in zip(sorted_png_dataset1, sorted_xml_dataset1):\n","        xml_files.append(str(DATASET_IMG / 'annotations'/ xml))\n","        png_files.append(str(DATASET_IMG / 'images' / png))\n","\n","    for png, xml in zip(sorted_png_dataset2, sorted_xml_dataset2):\n","        xml_files.append(str(DATASET_CARS / 'annotations' / xml))\n","        png_files.append(str(DATASET_CARS / 'images' / png))\n","\n","    return xml_files, png_files\n","\n","def obtain_sift_features(gray_licensplates):\n","    sift = cv2.SIFT_create()\n","\n","    #For each image compute their sift features\n","    sift_features =  list(map(lambda gray_image: sift.detectAndCompute(gray_image, None)[1], gray_licensplates))\n","\n","    # Filter the images that have no sift features. Compress for each image all the sift features found in one row of shape (1, 128)\n","    sift_features = filter(lambda image_path: image_path is not None, sift_features)\n","    sift_features = list(map(lambda features: features.sum(0), sift_features))\n","\n","    sift_features = np.vstack(sift_features)\n","\n","    return sift_features"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"bDUCOnm-9jII"},"outputs":[],"source":["def constuct_samples():\n","    xml_files, png_files = read_files()\n","\n","    negative_samples_list = []\n","    licensplates = []\n","\n","    # Iterate trought the images\n","    for xml_path, img_path in zip(xml_files, png_files):\n","        # Obtain the licensplate\n","        licens_gray = licensplate(xml_path, img_path)\n","        if licens_gray is None:\n","            continue\n","        licensplates.append(licens_gray)\n","\n","    for idx, (xml_path, img_path) in enumerate(zip(xml_files, png_files)):\n","        if idx == 8:\n","            break\n","        # For each image obtain the regions that are not the licensplates.\n","        neg_samples = negative_samples(xml_path, img_path)\n","        negative_samples_list.extend(neg_samples)\n","\n","    return licensplates, negative_samples_list"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":10,"status":"error","timestamp":1695689676134,"user":{"displayName":"Adrián García Sebastián","userId":"00421830482348579797"},"user_tz":-120},"id":"B9YKf5ep9jII","outputId":"351c2578-cff8-406f-8246-42a53eaea23f"},"outputs":[],"source":["# Licensplates and non-licensplates\n","licensplates, negative_samples_list = constuct_samples()\n","\n","# For each of the licensplates and the things that are not licensplates obtain their sift-features\n","features_licensplate, negative_samples = obtain_sift_features(licensplates), obtain_sift_features(negative_samples_list)\n","\n","# Stack all the features in a single matrix called X. The matrix Y will stored the ground truth\n","X = np.vstack((features_licensplate, negative_samples))\n","\n","# 1 for Licensplate\n","ground_truth_licensplates = np.ones((len(features_licensplate), 1))\n","# 0 for not licensplate\n","ground_truht_negative_samples = np.zeros((len(negative_samples), 1))\n","\n","Y = np.vstack((ground_truth_licensplates, ground_truht_negative_samples))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"elapsed":303,"status":"error","timestamp":1695689691096,"user":{"displayName":"Adrián García Sebastián","userId":"00421830482348579797"},"user_tz":-120},"id":"tTYYYpd09jIJ","outputId":"4eacf70d-177b-488c-bcb2-e6f225ba1537"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n","y_train, y_test = y_train.ravel(), y_test.ravel()"]},{"cell_type":"markdown","metadata":{"id":"GmXmu2nG9jIK"},"source":["### Training"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"executionInfo":{"elapsed":335,"status":"error","timestamp":1695689702467,"user":{"displayName":"Adrián García Sebastián","userId":"00421830482348579797"},"user_tz":-120},"id":"lL3QaJXp9jIK","outputId":"3e4f4ade-51c4-483b-834e-f8e8bfcb2b19"},"outputs":[{"data":{"text/plain":["SVC()"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["clf_logistic = LogisticRegression(random_state=0, max_iter=20000)\n","clf_logistic.fit(X_train, y_train)\n","\n","clf_svm = svm.SVC(kernel='rbf', C=1.0)\n","clf_svm.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"sFvVB-0s9jIL"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYzcOYHJ9jIL","outputId":"5d1089f1-6e14-44cb-8a17-558515a5f9d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy score for logistic regression:\t0.8489208633093526\n","Accuracy score for SVM:\t0.8093525179856115\n"]}],"source":["y_pred_logistic = clf_logistic.predict(X_test)\n","y_pred_svm      = clf_svm.predict(X_test)\n","\n","accuracy_logistic = accuracy_score(y_pred_logistic, y_test)\n","accuracy_svm      = accuracy_score(y_pred_svm, y_test)\n","\n","print(\"Accuracy score for logistic regression:\\t{}\".format(accuracy_logistic))\n","print(\"Accuracy score for SVM:\\t{}\".format(accuracy_svm))"]},{"cell_type":"markdown","metadata":{"id":"h3mqjv7d9jIL"},"source":["### Store model in PKL file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1nBxLOSF9jIM"},"outputs":[],"source":["joblib.dump(svm_model, 'svm_model.pkl')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
